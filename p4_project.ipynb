{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12001d79",
   "metadata": {},
   "source": [
    "# Projet Auto ML - Part 4\n",
    "\n",
    "## Auteurs : \n",
    "<font size=\"3\"> ***BENDAOUD Islam***</font> \n",
    "\n",
    "<font size=\"3\"> ***ISSAAD Sarah***</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c1428e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e15fd0e",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f261584e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     17436\n",
      "1       565\n",
      "2       238\n",
      "3       132\n",
      "4        49\n",
      "5        40\n",
      "6        23\n",
      "7        14\n",
      "8        11\n",
      "9         9\n",
      "10        8\n",
      "11        5\n",
      "12        2\n",
      "Name: DValue, dtype: int64 0     16739\n",
      "1      1121\n",
      "2       327\n",
      "3       173\n",
      "4        60\n",
      "5        35\n",
      "6        23\n",
      "8        23\n",
      "7        12\n",
      "10        8\n",
      "9         7\n",
      "11        4\n",
      "Name: DWage, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Fifa 23 Players Data.csv')  \n",
    "df[\"BMI\"] = df['Weight(in kg)']/((df['Height(in cm)']/100)**2)\n",
    "data = df.drop(['Known As' , 'National Team Image Link' , 'Image Link'] ,axis = 1 )\n",
    "data = data.drop(['National Team Name','National Team Position' , 'Club Name' ], axis=1)\n",
    "data['Positions Played'] = data['Positions Played'].str.split(',').str[0]\n",
    "data['Height(in m)'] = data['Height(in cm)'] / 100\n",
    "\n",
    "#drop cm since it's 100% linear correlated to the heigh(m)\n",
    "data.drop('Height(in cm)' , axis=1, inplace=True)\n",
    "# Calculate BMI\n",
    "data['BMI'] = data['Weight(in kg)'] / (data['Height(in m)'] ** 2)\n",
    "data.drop('Weight(in kg)' , axis=1, inplace=True)\n",
    "\n",
    "def simple_pos(pos):\n",
    "    if pos in [\"RB\" , \"LB\" , \"RWB\" , \"LWB\" , \"CB\"] : \n",
    "        return 'DEF'\n",
    "    elif pos in [\"CDM\"  , \"CAM\" ,\"RM\"  , \"LM\"  , \"CM\"] : \n",
    "        return \"MID\"\n",
    "    elif pos in [\"CF\" , \"ST\" , \"LW\" , \"RW\" , \"LF\" , \"RF\"] : \n",
    "        return \"ATK\"\n",
    "    elif pos == \"GK\": \n",
    "        return \"GK\"\n",
    "    else :\n",
    "        return \"-\"\n",
    "    \n",
    "columns_to_change = [\"Best Position\" , \"Positions Played\", \"Club Position\"]\n",
    "data[columns_to_change] = data[columns_to_change].applymap(simple_pos)\n",
    "data = data.drop([\"Positions Played\" , \"Club Position\"] , axis = 1 )\n",
    "data = data.drop([\"National Team Jersey Number\" , \"Club Jersey Number\" , 'Contract Until' , 'On Loan'] , axis = 1 )\n",
    "\n",
    "def change_rates(rate ): \n",
    "    if rate == \"Medium\" : \n",
    "        return 2\n",
    "    elif rate == \"Low\" : \n",
    "        return 1\n",
    "    elif rate == \"High\" : \n",
    "        return 3\n",
    "\n",
    "columns_to_change = [\"Attacking Work Rate\" , \"Defensive Work Rate\"]\n",
    "data[columns_to_change] = data[columns_to_change].applymap(change_rates)\n",
    "\n",
    "\n",
    "def change_ages(age) : \n",
    "    if age < 20 : \n",
    "        return 0 \n",
    "    elif age >= 20 and age < 25 : \n",
    "        return 1 \n",
    "    if age >= 25 and age < 30 :\n",
    "        return 2\n",
    "    elif age >=30 and age <35 : \n",
    "        return 3\n",
    "    else : \n",
    "        return 4\n",
    "    \n",
    "columns_to_change = [\"Age\"]\n",
    "data[columns_to_change] = data[columns_to_change].applymap(change_ages)\n",
    "\n",
    "df_encoded = pd.get_dummies(data, columns=['Best Position', 'Preferred Foot'])\n",
    "\n",
    "# standardize the columns Value(in Euro) and Wage(in Euro) \n",
    "scaler = StandardScaler()\n",
    "df_encoded['Value(in Euro)'] = scaler.fit_transform(df_encoded[['Value(in Euro)']])\n",
    "df_encoded['Wage(in Euro)'] = scaler.fit_transform(df_encoded[['Wage(in Euro)']])\n",
    "\n",
    "\n",
    "\n",
    "df_encoded[\"DValue\"], bin_edges_value = pd.cut(df_encoded['Value(in Euro)'], bins = 20, labels=False, right=False, retbins=True)\n",
    "df_encoded[\"DWage\"], bin_edges_wage = pd.cut(df_encoded['Wage(in Euro)'], bins=20, labels=False, right=False, retbins=True)\n",
    "# drop where count of values is less than 3\n",
    "df_encoded = df_encoded.groupby('DValue').filter(lambda x: len(x) > 2)\n",
    "df_encoded = df_encoded.groupby('DWage').filter(lambda x: len(x) > 2)\n",
    "\n",
    "yw = df_encoded[\"DWage\"]\n",
    "yv = df_encoded[\"DValue\"]\n",
    "\n",
    "\n",
    "print(yv.value_counts() , yw.value_counts())\n",
    "\n",
    "X = df_encoded.drop(columns=['Nationality', \"DWage\" , \"DValue\", 'Overall', 'Full Name', 'Wage(in Euro)', 'Value(in Euro)'])\n",
    "\n",
    "\n",
    "\n",
    "Xw_train, Xw_test, yw_train, yw_test = train_test_split(X, yw, test_size=0.1,stratify = yw ,  random_state=42)\n",
    "Xv_train, Xv_test, yv_train, yv_test = train_test_split(X, yv, test_size=0.1,stratify = yv , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95266dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c2a670",
   "metadata": {},
   "source": [
    "# First Heuristic :  RandomSearch (with RandomizedSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a108e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Optimizing Linear Regression . . .')\n",
    "\n",
    "# Decision Tree\n",
    "dt_param_dist = {'max_depth': randint(1, 20),\n",
    "                 'min_samples_split': randint(2, 20),\n",
    "                 'min_samples_leaf': randint(1, 20)}\n",
    "\n",
    "dt_random_search_w = RandomizedSearchCV(LinearRegression(), dt_param_dist, n_iter=10, cv=2, n_jobs=-1)\n",
    "dt_random_search_w.fit(Xw_train, yw_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da40c001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing Decision Tree . . .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-23 {color: black;}#sk-container-id-23 pre{padding: 0;}#sk-container-id-23 div.sk-toggleable {background-color: white;}#sk-container-id-23 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-23 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-23 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-23 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-23 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-23 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-23 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-23 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-23 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-23 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-23 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-23 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-23 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-23 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-23 div.sk-item {position: relative;z-index: 1;}#sk-container-id-23 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-23 div.sk-item::before, #sk-container-id-23 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-23 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-23 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-23 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-23 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-23 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-23 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-23 div.sk-label-container {text-align: center;}#sk-container-id-23 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-23 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-23\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=2, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f998046e820&gt;,\n",
       "                                        &#x27;min_samples_leaf&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f99d3b10f70&gt;,\n",
       "                                        &#x27;min_samples_split&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f998043f730&gt;})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-57\" type=\"checkbox\" ><label for=\"sk-estimator-id-57\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=2, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f998046e820&gt;,\n",
       "                                        &#x27;min_samples_leaf&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f99d3b10f70&gt;,\n",
       "                                        &#x27;min_samples_split&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f998043f730&gt;})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-58\" type=\"checkbox\" ><label for=\"sk-estimator-id-58\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-59\" type=\"checkbox\" ><label for=\"sk-estimator-id-59\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=2, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f998046e820>,\n",
       "                                        'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f99d3b10f70>,\n",
       "                                        'min_samples_split': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f998043f730>})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Optimizing Decision Tree . . .')\n",
    "\n",
    "# Decision Tree\n",
    "dt_param_dist = {'max_depth': randint(1, 20),\n",
    "                 'min_samples_split': randint(2, 20),\n",
    "                 'min_samples_leaf': randint(1, 20)}\n",
    "\n",
    "dt_random_search_w = RandomizedSearchCV(DecisionTreeClassifier(), dt_param_dist, n_iter=10, cv=2, n_jobs=-1)\n",
    "dt_random_search_w.fit(Xw_train, yw_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ba52d1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-24 {color: black;}#sk-container-id-24 pre{padding: 0;}#sk-container-id-24 div.sk-toggleable {background-color: white;}#sk-container-id-24 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-24 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-24 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-24 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-24 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-24 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-24 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-24 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-24 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-24 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-24 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-24 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-24 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-24 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-24 div.sk-item {position: relative;z-index: 1;}#sk-container-id-24 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-24 div.sk-item::before, #sk-container-id-24 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-24 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-24 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-24 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-24 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-24 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-24 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-24 div.sk-label-container {text-align: center;}#sk-container-id-24 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-24 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-24\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=2, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f998046e820&gt;,\n",
       "                                        &#x27;min_samples_leaf&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f99d3b10f70&gt;,\n",
       "                                        &#x27;min_samples_split&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f998043f730&gt;})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-60\" type=\"checkbox\" ><label for=\"sk-estimator-id-60\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=2, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f998046e820&gt;,\n",
       "                                        &#x27;min_samples_leaf&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f99d3b10f70&gt;,\n",
       "                                        &#x27;min_samples_split&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f998043f730&gt;})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-61\" type=\"checkbox\" ><label for=\"sk-estimator-id-61\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-62\" type=\"checkbox\" ><label for=\"sk-estimator-id-62\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=2, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f998046e820>,\n",
       "                                        'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f99d3b10f70>,\n",
       "                                        'min_samples_split': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f998043f730>})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_random_search_v = RandomizedSearchCV(DecisionTreeClassifier(), dt_param_dist, n_iter=10, cv=2, n_jobs=-1)\n",
    "dt_random_search_v.fit(Xv_train, yv_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e23f6ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing LDA . . .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-25 {color: black;}#sk-container-id-25 pre{padding: 0;}#sk-container-id-25 div.sk-toggleable {background-color: white;}#sk-container-id-25 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-25 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-25 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-25 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-25 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-25 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-25 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-25 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-25 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-25 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-25 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-25 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-25 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-25 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-25 div.sk-item {position: relative;z-index: 1;}#sk-container-id-25 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-25 div.sk-item::before, #sk-container-id-25 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-25 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-25 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-25 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-25 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-25 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-25 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-25 div.sk-label-container {text-align: center;}#sk-container-id-25 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-25 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-25\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=2, estimator=LinearDiscriminantAnalysis(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;n_components&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f99a383f4f0&gt;})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-63\" type=\"checkbox\" ><label for=\"sk-estimator-id-63\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=2, estimator=LinearDiscriminantAnalysis(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;n_components&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f99a383f4f0&gt;})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-64\" type=\"checkbox\" ><label for=\"sk-estimator-id-64\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-65\" type=\"checkbox\" ><label for=\"sk-estimator-id-65\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=2, estimator=LinearDiscriminantAnalysis(), n_jobs=-1,\n",
       "                   param_distributions={'n_components': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f99a383f4f0>})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Optimizing LDA . . .')\n",
    "\n",
    "# Linear Discriminant Analysis (LDA)\n",
    "lda_param_dist = {'n_components': randint(1, min(Xw_train.shape[1], len(np.unique(yw_train))) - 1)}\n",
    "\n",
    "lda_random_search_w = RandomizedSearchCV(LinearDiscriminantAnalysis(), lda_param_dist, n_iter=10, cv=2, n_jobs=-1)\n",
    "lda_random_search_w.fit(Xw_train, yw_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "93824a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-26 {color: black;}#sk-container-id-26 pre{padding: 0;}#sk-container-id-26 div.sk-toggleable {background-color: white;}#sk-container-id-26 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-26 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-26 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-26 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-26 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-26 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-26 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-26 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-26 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-26 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-26 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-26 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-26 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-26 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-26 div.sk-item {position: relative;z-index: 1;}#sk-container-id-26 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-26 div.sk-item::before, #sk-container-id-26 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-26 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-26 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-26 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-26 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-26 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-26 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-26 div.sk-label-container {text-align: center;}#sk-container-id-26 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-26 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-26\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=2, estimator=LinearDiscriminantAnalysis(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;n_components&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f99a383f4f0&gt;})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-66\" type=\"checkbox\" ><label for=\"sk-estimator-id-66\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=2, estimator=LinearDiscriminantAnalysis(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;n_components&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f99a383f4f0&gt;})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-67\" type=\"checkbox\" ><label for=\"sk-estimator-id-67\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-68\" type=\"checkbox\" ><label for=\"sk-estimator-id-68\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=2, estimator=LinearDiscriminantAnalysis(), n_jobs=-1,\n",
       "                   param_distributions={'n_components': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f99a383f4f0>})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_random_search_v = RandomizedSearchCV(LinearDiscriminantAnalysis(), lda_param_dist, n_iter=10, cv=2, n_jobs=-1)\n",
    "lda_random_search_v.fit(Xv_train, yv_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9f4901c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming X_train_v, X_test, X_train_w, y_train_v, y_test, y_train_w are your data and labels\n",
    "\n",
    "# Function to get the best model and its performance\n",
    "def get_best_model_and_score(random_search, X_train, y_train, X_test, y_test):\n",
    "    best_model = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "\n",
    "    # Training performance\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "    # Test performance\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    return best_model, best_params, train_accuracy, test_accuracy\n",
    "\n",
    "# Get best models and scores\n",
    "lda_model_v, lda_params_v, lda_train_score_v, lda_test_score_v = get_best_model_and_score(lda_random_search_v, Xv_train, yv_train, Xv_test, yv_test)\n",
    "dt_model_v, dt_params_v, dt_train_score_v, dt_test_score_v = get_best_model_and_score(dt_random_search_v, Xv_train, yv_train, Xv_test, yv_test)\n",
    "dt_model_w, dt_params_w, dt_train_score_w, dt_test_score_w = get_best_model_and_score(dt_random_search_w, Xw_train, yw_train, Xw_test, yw_test)\n",
    "lda_model_w, lda_params_w, lda_train_score_w, lda_test_score_w = get_best_model_and_score(lda_random_search_w, Xw_train, yw_train, Xw_test, yw_test)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': ['LDA value', 'Decision Tree value' ,  'Decision Tree wage', 'LDA wage' ],\n",
    "    'Training Accuracy': [lda_train_score_v,dt_train_score_v, dt_train_score_w, lda_train_score_w ],\n",
    "    'Test Accuracy': [lda_test_score_v, dt_test_score_v, dt_test_score_w, lda_test_score_w]\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fcea41d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree value</td>\n",
       "      <td>0.987948</td>\n",
       "      <td>0.978425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LDA value</td>\n",
       "      <td>0.979554</td>\n",
       "      <td>0.975189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LDA wage</td>\n",
       "      <td>0.910961</td>\n",
       "      <td>0.912621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree wage</td>\n",
       "      <td>0.934944</td>\n",
       "      <td>0.910464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Training Accuracy  Test Accuracy\n",
       "1  Decision Tree value           0.987948       0.978425\n",
       "0            LDA value           0.979554       0.975189\n",
       "3             LDA wage           0.910961       0.912621\n",
       "2   Decision Tree wage           0.934944       0.910464"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = results_df.sort_values(by='Test Accuracy', ascending=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ba95e5",
   "metadata": {},
   "source": [
    "# Second Heuristic : Genetic Algorithm (with TPOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d1d8e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fb4d3ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "tpot_config = {\n",
    "    'sklearn.discriminant_analysis.LinearDiscriminantAnalysis': {\n",
    "        'n_components': list(range(1, min(X.shape[0], X.shape[1]))),\n",
    "        'solver': ['svd', 'lsqr', 'eigen'],\n",
    "        'shrinkage': [None, 'auto', 0.1, 0.5, 0.9],\n",
    "        'store_covariance': [True, False]\n",
    "    },\n",
    "    \n",
    "    'sklearn.tree.DecisionTreeClassifier': {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None] + list(range(1, 30)),\n",
    "        'min_samples_split': list(range(2, 30)),\n",
    "        'min_samples_leaf': list(range(1, 30)),\n",
    "        'splitter': ['best', 'random'],\n",
    "        'max_features': ['auto', 'sqrt', 'log2', None]\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.StandardScaler': {},  # Standardization step\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8f1dabea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tpot = TPOTClassifier(generations=30, population_size=100, verbosity=2, config_dict=tpot_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ed7648f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/3100 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.9833913798496434\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.9835712898946211\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.983871086039714\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.983871086039714\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.983871086039714\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.9839310380780834\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.9841109301464377\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.9841109481230609\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.9841709001614302\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.9841709001614302\n",
      "\n",
      "Generation 11 - Current best internal CV score: 0.9843510079492628\n",
      "\n",
      "Generation 12 - Current best internal CV score: 0.9844708940493782\n",
      "\n",
      "Generation 13 - Current best internal CV score: 0.9844708940493782\n",
      "\n",
      "Generation 14 - Current best internal CV score: 0.9844708940493782\n",
      "\n",
      "Generation 15 - Current best internal CV score: 0.9846508040943558\n",
      "\n",
      "Generation 16 - Current best internal CV score: 0.9846508040943558\n",
      "\n",
      "Generation 17 - Current best internal CV score: 0.9847108280392177\n",
      "\n",
      "Generation 18 - Current best internal CV score: 0.9847108280392177\n",
      "\n",
      "Generation 19 - Current best internal CV score: 0.9850702346668392\n",
      "\n",
      "Generation 20 - Current best internal CV score: 0.9850702346668392\n",
      "\n",
      "Generation 21 - Current best internal CV score: 0.9850702346668392\n",
      "\n",
      "Generation 22 - Current best internal CV score: 0.9850702346668392\n",
      "\n",
      "Generation 23 - Current best internal CV score: 0.9850702346668392\n",
      "\n",
      "Generation 24 - Current best internal CV score: 0.9850702346668392\n",
      "\n",
      "Generation 25 - Current best internal CV score: 0.9850702346668392\n",
      "\n",
      "Generation 26 - Current best internal CV score: 0.9850702346668392\n",
      "\n",
      "Generation 27 - Current best internal CV score: 0.9850702346668392\n",
      "\n",
      "Generation 28 - Current best internal CV score: 0.9850702346668392\n",
      "\n",
      "Generation 29 - Current best internal CV score: 0.9850702346668392\n",
      "\n",
      "Generation 30 - Current best internal CV score: 0.9850702346668392\n",
      "\n",
      "Best pipeline: LinearDiscriminantAnalysis(DecisionTreeClassifier(DecisionTreeClassifier(input_matrix, criterion=gini, max_depth=10, max_features=None, min_samples_leaf=11, min_samples_split=13, splitter=best), criterion=entropy, max_depth=29, max_features=None, min_samples_leaf=27, min_samples_split=12, splitter=random), n_components=10, shrinkage=None, solver=svd, store_covariance=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-29 {color: black;}#sk-container-id-29 pre{padding: 0;}#sk-container-id-29 div.sk-toggleable {background-color: white;}#sk-container-id-29 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-29 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-29 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-29 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-29 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-29 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-29 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-29 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-29 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-29 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-29 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-29 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-29 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-29 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-29 div.sk-item {position: relative;z-index: 1;}#sk-container-id-29 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-29 div.sk-item::before, #sk-container-id-29 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-29 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-29 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-29 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-29 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-29 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-29 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-29 div.sk-label-container {text-align: center;}#sk-container-id-29 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-29 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-29\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TPOTClassifier(config_dict={&#x27;sklearn.discriminant_analysis.LinearDiscriminantAnalysis&#x27;: {&#x27;n_components&#x27;: [1,\n",
       "                                                                                                          2,\n",
       "                                                                                                          3,\n",
       "                                                                                                          4,\n",
       "                                                                                                          5,\n",
       "                                                                                                          6,\n",
       "                                                                                                          7,\n",
       "                                                                                                          8,\n",
       "                                                                                                          9,\n",
       "                                                                                                          10,\n",
       "                                                                                                          11,\n",
       "                                                                                                          12,\n",
       "                                                                                                          13,\n",
       "                                                                                                          14,\n",
       "                                                                                                          15,\n",
       "                                                                                                          16,\n",
       "                                                                                                          17,\n",
       "                                                                                                          18,\n",
       "                                                                                                          19,\n",
       "                                                                                                          20,\n",
       "                                                                                                          21,\n",
       "                                                                                                          22,\n",
       "                                                                                                          23,\n",
       "                                                                                                          24,\n",
       "                                                                                                          25,\n",
       "                                                                                                          26,\n",
       "                                                                                                          27,\n",
       "                                                                                                          28,\n",
       "                                                                                                          29,\n",
       "                                                                                                          30, ...],\n",
       "                                                                                         &#x27;shrinkage&#x27;: [None,\n",
       "                                                                                                       &#x27;auto&#x27;,\n",
       "                                                                                                       0.1,\n",
       "                                                                                                       0.5,\n",
       "                                                                                                       0.9],\n",
       "                                                                                         &#x27;solver&#x27;: [&#x27;svd&#x27;,\n",
       "                                                                                                    &#x27;lsqr&#x27;,\n",
       "                                                                                                    &#x27;eigen&#x27;],\n",
       "                                                                                         &#x27;store_covariance&#x27;: [True,\n",
       "                                                                                                              False]},\n",
       "                            &#x27;sklearn.preprocessing.StandardScaler&#x27;: {},\n",
       "                            &#x27;sklearn.tree.D...\n",
       "                                                                                  13,\n",
       "                                                                                  14,\n",
       "                                                                                  15,\n",
       "                                                                                  16,\n",
       "                                                                                  17,\n",
       "                                                                                  18,\n",
       "                                                                                  19,\n",
       "                                                                                  20,\n",
       "                                                                                  21,\n",
       "                                                                                  22,\n",
       "                                                                                  23,\n",
       "                                                                                  24,\n",
       "                                                                                  25,\n",
       "                                                                                  26,\n",
       "                                                                                  27,\n",
       "                                                                                  28,\n",
       "                                                                                  29],\n",
       "                                                                    &#x27;max_features&#x27;: [&#x27;auto&#x27;,\n",
       "                                                                                     &#x27;sqrt&#x27;,\n",
       "                                                                                     &#x27;log2&#x27;,\n",
       "                                                                                     None],\n",
       "                                                                    &#x27;min_samples_leaf&#x27;: [1,\n",
       "                                                                                         2,\n",
       "                                                                                         3,\n",
       "                                                                                         4,\n",
       "                                                                                         5,\n",
       "                                                                                         6,\n",
       "                                                                                         7,\n",
       "                                                                                         8,\n",
       "                                                                                         9,\n",
       "                                                                                         10,\n",
       "                                                                                         11,\n",
       "                                                                                         12,\n",
       "                                                                                         13,\n",
       "                                                                                         14,\n",
       "                                                                                         15,\n",
       "                                                                                         16,\n",
       "                                                                                         17,\n",
       "                                                                                         18,\n",
       "                                                                                         19,\n",
       "                                                                                         20,\n",
       "                                                                                         21,\n",
       "                                                                                         22,\n",
       "                                                                                         23,\n",
       "                                                                                         24,\n",
       "                                                                                         25,\n",
       "                                                                                         26,\n",
       "                                                                                         27,\n",
       "                                                                                         28,\n",
       "                                                                                         29],\n",
       "                                                                    &#x27;min_samples_split&#x27;: [2,\n",
       "                                                                                          3,\n",
       "                                                                                          4,\n",
       "                                                                                          5,\n",
       "                                                                                          6,\n",
       "                                                                                          7,\n",
       "                                                                                          8,\n",
       "                                                                                          9,\n",
       "                                                                                          10,\n",
       "                                                                                          11,\n",
       "                                                                                          12,\n",
       "                                                                                          13,\n",
       "                                                                                          14,\n",
       "                                                                                          15,\n",
       "                                                                                          16,\n",
       "                                                                                          17,\n",
       "                                                                                          18,\n",
       "                                                                                          19,\n",
       "                                                                                          20,\n",
       "                                                                                          21,\n",
       "                                                                                          22,\n",
       "                                                                                          23,\n",
       "                                                                                          24,\n",
       "                                                                                          25,\n",
       "                                                                                          26,\n",
       "                                                                                          27,\n",
       "                                                                                          28,\n",
       "                                                                                          29],\n",
       "                                                                    &#x27;splitter&#x27;: [&#x27;best&#x27;,\n",
       "                                                                                 &#x27;random&#x27;]}},\n",
       "               generations=30, verbosity=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-71\" type=\"checkbox\" checked><label for=\"sk-estimator-id-71\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TPOTClassifier</label><div class=\"sk-toggleable__content\"><pre>TPOTClassifier(config_dict={&#x27;sklearn.discriminant_analysis.LinearDiscriminantAnalysis&#x27;: {&#x27;n_components&#x27;: [1,\n",
       "                                                                                                          2,\n",
       "                                                                                                          3,\n",
       "                                                                                                          4,\n",
       "                                                                                                          5,\n",
       "                                                                                                          6,\n",
       "                                                                                                          7,\n",
       "                                                                                                          8,\n",
       "                                                                                                          9,\n",
       "                                                                                                          10,\n",
       "                                                                                                          11,\n",
       "                                                                                                          12,\n",
       "                                                                                                          13,\n",
       "                                                                                                          14,\n",
       "                                                                                                          15,\n",
       "                                                                                                          16,\n",
       "                                                                                                          17,\n",
       "                                                                                                          18,\n",
       "                                                                                                          19,\n",
       "                                                                                                          20,\n",
       "                                                                                                          21,\n",
       "                                                                                                          22,\n",
       "                                                                                                          23,\n",
       "                                                                                                          24,\n",
       "                                                                                                          25,\n",
       "                                                                                                          26,\n",
       "                                                                                                          27,\n",
       "                                                                                                          28,\n",
       "                                                                                                          29,\n",
       "                                                                                                          30, ...],\n",
       "                                                                                         &#x27;shrinkage&#x27;: [None,\n",
       "                                                                                                       &#x27;auto&#x27;,\n",
       "                                                                                                       0.1,\n",
       "                                                                                                       0.5,\n",
       "                                                                                                       0.9],\n",
       "                                                                                         &#x27;solver&#x27;: [&#x27;svd&#x27;,\n",
       "                                                                                                    &#x27;lsqr&#x27;,\n",
       "                                                                                                    &#x27;eigen&#x27;],\n",
       "                                                                                         &#x27;store_covariance&#x27;: [True,\n",
       "                                                                                                              False]},\n",
       "                            &#x27;sklearn.preprocessing.StandardScaler&#x27;: {},\n",
       "                            &#x27;sklearn.tree.D...\n",
       "                                                                                  13,\n",
       "                                                                                  14,\n",
       "                                                                                  15,\n",
       "                                                                                  16,\n",
       "                                                                                  17,\n",
       "                                                                                  18,\n",
       "                                                                                  19,\n",
       "                                                                                  20,\n",
       "                                                                                  21,\n",
       "                                                                                  22,\n",
       "                                                                                  23,\n",
       "                                                                                  24,\n",
       "                                                                                  25,\n",
       "                                                                                  26,\n",
       "                                                                                  27,\n",
       "                                                                                  28,\n",
       "                                                                                  29],\n",
       "                                                                    &#x27;max_features&#x27;: [&#x27;auto&#x27;,\n",
       "                                                                                     &#x27;sqrt&#x27;,\n",
       "                                                                                     &#x27;log2&#x27;,\n",
       "                                                                                     None],\n",
       "                                                                    &#x27;min_samples_leaf&#x27;: [1,\n",
       "                                                                                         2,\n",
       "                                                                                         3,\n",
       "                                                                                         4,\n",
       "                                                                                         5,\n",
       "                                                                                         6,\n",
       "                                                                                         7,\n",
       "                                                                                         8,\n",
       "                                                                                         9,\n",
       "                                                                                         10,\n",
       "                                                                                         11,\n",
       "                                                                                         12,\n",
       "                                                                                         13,\n",
       "                                                                                         14,\n",
       "                                                                                         15,\n",
       "                                                                                         16,\n",
       "                                                                                         17,\n",
       "                                                                                         18,\n",
       "                                                                                         19,\n",
       "                                                                                         20,\n",
       "                                                                                         21,\n",
       "                                                                                         22,\n",
       "                                                                                         23,\n",
       "                                                                                         24,\n",
       "                                                                                         25,\n",
       "                                                                                         26,\n",
       "                                                                                         27,\n",
       "                                                                                         28,\n",
       "                                                                                         29],\n",
       "                                                                    &#x27;min_samples_split&#x27;: [2,\n",
       "                                                                                          3,\n",
       "                                                                                          4,\n",
       "                                                                                          5,\n",
       "                                                                                          6,\n",
       "                                                                                          7,\n",
       "                                                                                          8,\n",
       "                                                                                          9,\n",
       "                                                                                          10,\n",
       "                                                                                          11,\n",
       "                                                                                          12,\n",
       "                                                                                          13,\n",
       "                                                                                          14,\n",
       "                                                                                          15,\n",
       "                                                                                          16,\n",
       "                                                                                          17,\n",
       "                                                                                          18,\n",
       "                                                                                          19,\n",
       "                                                                                          20,\n",
       "                                                                                          21,\n",
       "                                                                                          22,\n",
       "                                                                                          23,\n",
       "                                                                                          24,\n",
       "                                                                                          25,\n",
       "                                                                                          26,\n",
       "                                                                                          27,\n",
       "                                                                                          28,\n",
       "                                                                                          29],\n",
       "                                                                    &#x27;splitter&#x27;: [&#x27;best&#x27;,\n",
       "                                                                                 &#x27;random&#x27;]}},\n",
       "               generations=30, verbosity=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TPOTClassifier(config_dict={'sklearn.discriminant_analysis.LinearDiscriminantAnalysis': {'n_components': [1,\n",
       "                                                                                                          2,\n",
       "                                                                                                          3,\n",
       "                                                                                                          4,\n",
       "                                                                                                          5,\n",
       "                                                                                                          6,\n",
       "                                                                                                          7,\n",
       "                                                                                                          8,\n",
       "                                                                                                          9,\n",
       "                                                                                                          10,\n",
       "                                                                                                          11,\n",
       "                                                                                                          12,\n",
       "                                                                                                          13,\n",
       "                                                                                                          14,\n",
       "                                                                                                          15,\n",
       "                                                                                                          16,\n",
       "                                                                                                          17,\n",
       "                                                                                                          18,\n",
       "                                                                                                          19,\n",
       "                                                                                                          20,\n",
       "                                                                                                          21,\n",
       "                                                                                                          22,\n",
       "                                                                                                          23,\n",
       "                                                                                                          24,\n",
       "                                                                                                          25,\n",
       "                                                                                                          26,\n",
       "                                                                                                          27,\n",
       "                                                                                                          28,\n",
       "                                                                                                          29,\n",
       "                                                                                                          30, ...],\n",
       "                                                                                         'shrinkage': [None,\n",
       "                                                                                                       'auto',\n",
       "                                                                                                       0.1,\n",
       "                                                                                                       0.5,\n",
       "                                                                                                       0.9],\n",
       "                                                                                         'solver': ['svd',\n",
       "                                                                                                    'lsqr',\n",
       "                                                                                                    'eigen'],\n",
       "                                                                                         'store_covariance': [True,\n",
       "                                                                                                              False]},\n",
       "                            'sklearn.preprocessing.StandardScaler': {},\n",
       "                            'sklearn.tree.D...\n",
       "                                                                                  13,\n",
       "                                                                                  14,\n",
       "                                                                                  15,\n",
       "                                                                                  16,\n",
       "                                                                                  17,\n",
       "                                                                                  18,\n",
       "                                                                                  19,\n",
       "                                                                                  20,\n",
       "                                                                                  21,\n",
       "                                                                                  22,\n",
       "                                                                                  23,\n",
       "                                                                                  24,\n",
       "                                                                                  25,\n",
       "                                                                                  26,\n",
       "                                                                                  27,\n",
       "                                                                                  28,\n",
       "                                                                                  29],\n",
       "                                                                    'max_features': ['auto',\n",
       "                                                                                     'sqrt',\n",
       "                                                                                     'log2',\n",
       "                                                                                     None],\n",
       "                                                                    'min_samples_leaf': [1,\n",
       "                                                                                         2,\n",
       "                                                                                         3,\n",
       "                                                                                         4,\n",
       "                                                                                         5,\n",
       "                                                                                         6,\n",
       "                                                                                         7,\n",
       "                                                                                         8,\n",
       "                                                                                         9,\n",
       "                                                                                         10,\n",
       "                                                                                         11,\n",
       "                                                                                         12,\n",
       "                                                                                         13,\n",
       "                                                                                         14,\n",
       "                                                                                         15,\n",
       "                                                                                         16,\n",
       "                                                                                         17,\n",
       "                                                                                         18,\n",
       "                                                                                         19,\n",
       "                                                                                         20,\n",
       "                                                                                         21,\n",
       "                                                                                         22,\n",
       "                                                                                         23,\n",
       "                                                                                         24,\n",
       "                                                                                         25,\n",
       "                                                                                         26,\n",
       "                                                                                         27,\n",
       "                                                                                         28,\n",
       "                                                                                         29],\n",
       "                                                                    'min_samples_split': [2,\n",
       "                                                                                          3,\n",
       "                                                                                          4,\n",
       "                                                                                          5,\n",
       "                                                                                          6,\n",
       "                                                                                          7,\n",
       "                                                                                          8,\n",
       "                                                                                          9,\n",
       "                                                                                          10,\n",
       "                                                                                          11,\n",
       "                                                                                          12,\n",
       "                                                                                          13,\n",
       "                                                                                          14,\n",
       "                                                                                          15,\n",
       "                                                                                          16,\n",
       "                                                                                          17,\n",
       "                                                                                          18,\n",
       "                                                                                          19,\n",
       "                                                                                          20,\n",
       "                                                                                          21,\n",
       "                                                                                          22,\n",
       "                                                                                          23,\n",
       "                                                                                          24,\n",
       "                                                                                          25,\n",
       "                                                                                          26,\n",
       "                                                                                          27,\n",
       "                                                                                          28,\n",
       "                                                                                          29],\n",
       "                                                                    'splitter': ['best',\n",
       "                                                                                 'random']}},\n",
       "               generations=30, verbosity=2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.fit(Xv_train, yv_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0ba2e909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.982200647249191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/islambendaoud/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/islambendaoud/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(tpot.score(Xv_test, yv_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b611c896",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.export('tpot_digits_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "57e5b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tpotw = TPOTClassifier(generations=30, population_size=100, verbosity=2, config_dict=tpot_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "668b62c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/3100 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.9123998612204689\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.9123998612204689\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.912579465662852\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.912579465662852\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.9128790640650898\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.9131193396107701\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.9140184583967009\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.9145578110225461\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.9153972114662092\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.9153972114662092\n",
      "\n",
      "Generation 11 - Current best internal CV score: 0.9153972114662092\n",
      "\n",
      "Generation 12 - Current best internal CV score: 0.9153972114662092\n",
      "\n",
      "Generation 13 - Current best internal CV score: 0.9153972114662092\n",
      "\n",
      "Generation 14 - Current best internal CV score: 0.9153972114662092\n",
      "\n",
      "Generation 15 - Current best internal CV score: 0.9153972114662092\n",
      "\n",
      "Generation 16 - Current best internal CV score: 0.9153972114662092\n",
      "\n",
      "Generation 17 - Current best internal CV score: 0.9156972053541574\n",
      "\n",
      "Generation 18 - Current best internal CV score: 0.9156972053541574\n",
      "\n",
      "Generation 19 - Current best internal CV score: 0.9156972053541574\n",
      "\n",
      "Generation 20 - Current best internal CV score: 0.9156972053541574\n",
      "\n",
      "Generation 21 - Current best internal CV score: 0.9156972053541574\n",
      "\n",
      "Generation 22 - Current best internal CV score: 0.9156972053541574\n",
      "\n",
      "Generation 23 - Current best internal CV score: 0.9156972053541574\n",
      "\n",
      "Generation 24 - Current best internal CV score: 0.9156972053541574\n",
      "\n",
      "Generation 25 - Current best internal CV score: 0.9156972053541574\n",
      "\n",
      "Generation 26 - Current best internal CV score: 0.9156972053541574\n",
      "\n",
      "Generation 27 - Current best internal CV score: 0.9156972053541574\n",
      "\n",
      "Generation 28 - Current best internal CV score: 0.9156972053541574\n",
      "\n",
      "Generation 29 - Current best internal CV score: 0.9156972053541574\n",
      "\n",
      "Generation 30 - Current best internal CV score: 0.9156972053541574\n",
      "\n",
      "Best pipeline: DecisionTreeClassifier(DecisionTreeClassifier(StandardScaler(input_matrix), criterion=entropy, max_depth=4, max_features=None, min_samples_leaf=8, min_samples_split=9, splitter=random), criterion=gini, max_depth=4, max_features=None, min_samples_leaf=21, min_samples_split=12, splitter=best)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-30 {color: black;}#sk-container-id-30 pre{padding: 0;}#sk-container-id-30 div.sk-toggleable {background-color: white;}#sk-container-id-30 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-30 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-30 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-30 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-30 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-30 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-30 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-30 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-30 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-30 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-30 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-30 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-30 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-30 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-30 div.sk-item {position: relative;z-index: 1;}#sk-container-id-30 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-30 div.sk-item::before, #sk-container-id-30 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-30 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-30 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-30 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-30 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-30 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-30 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-30 div.sk-label-container {text-align: center;}#sk-container-id-30 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-30 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-30\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TPOTClassifier(config_dict={&#x27;sklearn.discriminant_analysis.LinearDiscriminantAnalysis&#x27;: {&#x27;n_components&#x27;: [1,\n",
       "                                                                                                          2,\n",
       "                                                                                                          3,\n",
       "                                                                                                          4,\n",
       "                                                                                                          5,\n",
       "                                                                                                          6,\n",
       "                                                                                                          7,\n",
       "                                                                                                          8,\n",
       "                                                                                                          9,\n",
       "                                                                                                          10,\n",
       "                                                                                                          11,\n",
       "                                                                                                          12,\n",
       "                                                                                                          13,\n",
       "                                                                                                          14,\n",
       "                                                                                                          15,\n",
       "                                                                                                          16,\n",
       "                                                                                                          17,\n",
       "                                                                                                          18,\n",
       "                                                                                                          19,\n",
       "                                                                                                          20,\n",
       "                                                                                                          21,\n",
       "                                                                                                          22,\n",
       "                                                                                                          23,\n",
       "                                                                                                          24,\n",
       "                                                                                                          25,\n",
       "                                                                                                          26,\n",
       "                                                                                                          27,\n",
       "                                                                                                          28,\n",
       "                                                                                                          29,\n",
       "                                                                                                          30, ...],\n",
       "                                                                                         &#x27;shrinkage&#x27;: [None,\n",
       "                                                                                                       &#x27;auto&#x27;,\n",
       "                                                                                                       0.1,\n",
       "                                                                                                       0.5,\n",
       "                                                                                                       0.9],\n",
       "                                                                                         &#x27;solver&#x27;: [&#x27;svd&#x27;,\n",
       "                                                                                                    &#x27;lsqr&#x27;,\n",
       "                                                                                                    &#x27;eigen&#x27;],\n",
       "                                                                                         &#x27;store_covariance&#x27;: [True,\n",
       "                                                                                                              False]},\n",
       "                            &#x27;sklearn.preprocessing.StandardScaler&#x27;: {},\n",
       "                            &#x27;sklearn.tree.D...\n",
       "                                                                                  13,\n",
       "                                                                                  14,\n",
       "                                                                                  15,\n",
       "                                                                                  16,\n",
       "                                                                                  17,\n",
       "                                                                                  18,\n",
       "                                                                                  19,\n",
       "                                                                                  20,\n",
       "                                                                                  21,\n",
       "                                                                                  22,\n",
       "                                                                                  23,\n",
       "                                                                                  24,\n",
       "                                                                                  25,\n",
       "                                                                                  26,\n",
       "                                                                                  27,\n",
       "                                                                                  28,\n",
       "                                                                                  29],\n",
       "                                                                    &#x27;max_features&#x27;: [&#x27;auto&#x27;,\n",
       "                                                                                     &#x27;sqrt&#x27;,\n",
       "                                                                                     &#x27;log2&#x27;,\n",
       "                                                                                     None],\n",
       "                                                                    &#x27;min_samples_leaf&#x27;: [1,\n",
       "                                                                                         2,\n",
       "                                                                                         3,\n",
       "                                                                                         4,\n",
       "                                                                                         5,\n",
       "                                                                                         6,\n",
       "                                                                                         7,\n",
       "                                                                                         8,\n",
       "                                                                                         9,\n",
       "                                                                                         10,\n",
       "                                                                                         11,\n",
       "                                                                                         12,\n",
       "                                                                                         13,\n",
       "                                                                                         14,\n",
       "                                                                                         15,\n",
       "                                                                                         16,\n",
       "                                                                                         17,\n",
       "                                                                                         18,\n",
       "                                                                                         19,\n",
       "                                                                                         20,\n",
       "                                                                                         21,\n",
       "                                                                                         22,\n",
       "                                                                                         23,\n",
       "                                                                                         24,\n",
       "                                                                                         25,\n",
       "                                                                                         26,\n",
       "                                                                                         27,\n",
       "                                                                                         28,\n",
       "                                                                                         29],\n",
       "                                                                    &#x27;min_samples_split&#x27;: [2,\n",
       "                                                                                          3,\n",
       "                                                                                          4,\n",
       "                                                                                          5,\n",
       "                                                                                          6,\n",
       "                                                                                          7,\n",
       "                                                                                          8,\n",
       "                                                                                          9,\n",
       "                                                                                          10,\n",
       "                                                                                          11,\n",
       "                                                                                          12,\n",
       "                                                                                          13,\n",
       "                                                                                          14,\n",
       "                                                                                          15,\n",
       "                                                                                          16,\n",
       "                                                                                          17,\n",
       "                                                                                          18,\n",
       "                                                                                          19,\n",
       "                                                                                          20,\n",
       "                                                                                          21,\n",
       "                                                                                          22,\n",
       "                                                                                          23,\n",
       "                                                                                          24,\n",
       "                                                                                          25,\n",
       "                                                                                          26,\n",
       "                                                                                          27,\n",
       "                                                                                          28,\n",
       "                                                                                          29],\n",
       "                                                                    &#x27;splitter&#x27;: [&#x27;best&#x27;,\n",
       "                                                                                 &#x27;random&#x27;]}},\n",
       "               generations=30, verbosity=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-72\" type=\"checkbox\" checked><label for=\"sk-estimator-id-72\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TPOTClassifier</label><div class=\"sk-toggleable__content\"><pre>TPOTClassifier(config_dict={&#x27;sklearn.discriminant_analysis.LinearDiscriminantAnalysis&#x27;: {&#x27;n_components&#x27;: [1,\n",
       "                                                                                                          2,\n",
       "                                                                                                          3,\n",
       "                                                                                                          4,\n",
       "                                                                                                          5,\n",
       "                                                                                                          6,\n",
       "                                                                                                          7,\n",
       "                                                                                                          8,\n",
       "                                                                                                          9,\n",
       "                                                                                                          10,\n",
       "                                                                                                          11,\n",
       "                                                                                                          12,\n",
       "                                                                                                          13,\n",
       "                                                                                                          14,\n",
       "                                                                                                          15,\n",
       "                                                                                                          16,\n",
       "                                                                                                          17,\n",
       "                                                                                                          18,\n",
       "                                                                                                          19,\n",
       "                                                                                                          20,\n",
       "                                                                                                          21,\n",
       "                                                                                                          22,\n",
       "                                                                                                          23,\n",
       "                                                                                                          24,\n",
       "                                                                                                          25,\n",
       "                                                                                                          26,\n",
       "                                                                                                          27,\n",
       "                                                                                                          28,\n",
       "                                                                                                          29,\n",
       "                                                                                                          30, ...],\n",
       "                                                                                         &#x27;shrinkage&#x27;: [None,\n",
       "                                                                                                       &#x27;auto&#x27;,\n",
       "                                                                                                       0.1,\n",
       "                                                                                                       0.5,\n",
       "                                                                                                       0.9],\n",
       "                                                                                         &#x27;solver&#x27;: [&#x27;svd&#x27;,\n",
       "                                                                                                    &#x27;lsqr&#x27;,\n",
       "                                                                                                    &#x27;eigen&#x27;],\n",
       "                                                                                         &#x27;store_covariance&#x27;: [True,\n",
       "                                                                                                              False]},\n",
       "                            &#x27;sklearn.preprocessing.StandardScaler&#x27;: {},\n",
       "                            &#x27;sklearn.tree.D...\n",
       "                                                                                  13,\n",
       "                                                                                  14,\n",
       "                                                                                  15,\n",
       "                                                                                  16,\n",
       "                                                                                  17,\n",
       "                                                                                  18,\n",
       "                                                                                  19,\n",
       "                                                                                  20,\n",
       "                                                                                  21,\n",
       "                                                                                  22,\n",
       "                                                                                  23,\n",
       "                                                                                  24,\n",
       "                                                                                  25,\n",
       "                                                                                  26,\n",
       "                                                                                  27,\n",
       "                                                                                  28,\n",
       "                                                                                  29],\n",
       "                                                                    &#x27;max_features&#x27;: [&#x27;auto&#x27;,\n",
       "                                                                                     &#x27;sqrt&#x27;,\n",
       "                                                                                     &#x27;log2&#x27;,\n",
       "                                                                                     None],\n",
       "                                                                    &#x27;min_samples_leaf&#x27;: [1,\n",
       "                                                                                         2,\n",
       "                                                                                         3,\n",
       "                                                                                         4,\n",
       "                                                                                         5,\n",
       "                                                                                         6,\n",
       "                                                                                         7,\n",
       "                                                                                         8,\n",
       "                                                                                         9,\n",
       "                                                                                         10,\n",
       "                                                                                         11,\n",
       "                                                                                         12,\n",
       "                                                                                         13,\n",
       "                                                                                         14,\n",
       "                                                                                         15,\n",
       "                                                                                         16,\n",
       "                                                                                         17,\n",
       "                                                                                         18,\n",
       "                                                                                         19,\n",
       "                                                                                         20,\n",
       "                                                                                         21,\n",
       "                                                                                         22,\n",
       "                                                                                         23,\n",
       "                                                                                         24,\n",
       "                                                                                         25,\n",
       "                                                                                         26,\n",
       "                                                                                         27,\n",
       "                                                                                         28,\n",
       "                                                                                         29],\n",
       "                                                                    &#x27;min_samples_split&#x27;: [2,\n",
       "                                                                                          3,\n",
       "                                                                                          4,\n",
       "                                                                                          5,\n",
       "                                                                                          6,\n",
       "                                                                                          7,\n",
       "                                                                                          8,\n",
       "                                                                                          9,\n",
       "                                                                                          10,\n",
       "                                                                                          11,\n",
       "                                                                                          12,\n",
       "                                                                                          13,\n",
       "                                                                                          14,\n",
       "                                                                                          15,\n",
       "                                                                                          16,\n",
       "                                                                                          17,\n",
       "                                                                                          18,\n",
       "                                                                                          19,\n",
       "                                                                                          20,\n",
       "                                                                                          21,\n",
       "                                                                                          22,\n",
       "                                                                                          23,\n",
       "                                                                                          24,\n",
       "                                                                                          25,\n",
       "                                                                                          26,\n",
       "                                                                                          27,\n",
       "                                                                                          28,\n",
       "                                                                                          29],\n",
       "                                                                    &#x27;splitter&#x27;: [&#x27;best&#x27;,\n",
       "                                                                                 &#x27;random&#x27;]}},\n",
       "               generations=30, verbosity=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TPOTClassifier(config_dict={'sklearn.discriminant_analysis.LinearDiscriminantAnalysis': {'n_components': [1,\n",
       "                                                                                                          2,\n",
       "                                                                                                          3,\n",
       "                                                                                                          4,\n",
       "                                                                                                          5,\n",
       "                                                                                                          6,\n",
       "                                                                                                          7,\n",
       "                                                                                                          8,\n",
       "                                                                                                          9,\n",
       "                                                                                                          10,\n",
       "                                                                                                          11,\n",
       "                                                                                                          12,\n",
       "                                                                                                          13,\n",
       "                                                                                                          14,\n",
       "                                                                                                          15,\n",
       "                                                                                                          16,\n",
       "                                                                                                          17,\n",
       "                                                                                                          18,\n",
       "                                                                                                          19,\n",
       "                                                                                                          20,\n",
       "                                                                                                          21,\n",
       "                                                                                                          22,\n",
       "                                                                                                          23,\n",
       "                                                                                                          24,\n",
       "                                                                                                          25,\n",
       "                                                                                                          26,\n",
       "                                                                                                          27,\n",
       "                                                                                                          28,\n",
       "                                                                                                          29,\n",
       "                                                                                                          30, ...],\n",
       "                                                                                         'shrinkage': [None,\n",
       "                                                                                                       'auto',\n",
       "                                                                                                       0.1,\n",
       "                                                                                                       0.5,\n",
       "                                                                                                       0.9],\n",
       "                                                                                         'solver': ['svd',\n",
       "                                                                                                    'lsqr',\n",
       "                                                                                                    'eigen'],\n",
       "                                                                                         'store_covariance': [True,\n",
       "                                                                                                              False]},\n",
       "                            'sklearn.preprocessing.StandardScaler': {},\n",
       "                            'sklearn.tree.D...\n",
       "                                                                                  13,\n",
       "                                                                                  14,\n",
       "                                                                                  15,\n",
       "                                                                                  16,\n",
       "                                                                                  17,\n",
       "                                                                                  18,\n",
       "                                                                                  19,\n",
       "                                                                                  20,\n",
       "                                                                                  21,\n",
       "                                                                                  22,\n",
       "                                                                                  23,\n",
       "                                                                                  24,\n",
       "                                                                                  25,\n",
       "                                                                                  26,\n",
       "                                                                                  27,\n",
       "                                                                                  28,\n",
       "                                                                                  29],\n",
       "                                                                    'max_features': ['auto',\n",
       "                                                                                     'sqrt',\n",
       "                                                                                     'log2',\n",
       "                                                                                     None],\n",
       "                                                                    'min_samples_leaf': [1,\n",
       "                                                                                         2,\n",
       "                                                                                         3,\n",
       "                                                                                         4,\n",
       "                                                                                         5,\n",
       "                                                                                         6,\n",
       "                                                                                         7,\n",
       "                                                                                         8,\n",
       "                                                                                         9,\n",
       "                                                                                         10,\n",
       "                                                                                         11,\n",
       "                                                                                         12,\n",
       "                                                                                         13,\n",
       "                                                                                         14,\n",
       "                                                                                         15,\n",
       "                                                                                         16,\n",
       "                                                                                         17,\n",
       "                                                                                         18,\n",
       "                                                                                         19,\n",
       "                                                                                         20,\n",
       "                                                                                         21,\n",
       "                                                                                         22,\n",
       "                                                                                         23,\n",
       "                                                                                         24,\n",
       "                                                                                         25,\n",
       "                                                                                         26,\n",
       "                                                                                         27,\n",
       "                                                                                         28,\n",
       "                                                                                         29],\n",
       "                                                                    'min_samples_split': [2,\n",
       "                                                                                          3,\n",
       "                                                                                          4,\n",
       "                                                                                          5,\n",
       "                                                                                          6,\n",
       "                                                                                          7,\n",
       "                                                                                          8,\n",
       "                                                                                          9,\n",
       "                                                                                          10,\n",
       "                                                                                          11,\n",
       "                                                                                          12,\n",
       "                                                                                          13,\n",
       "                                                                                          14,\n",
       "                                                                                          15,\n",
       "                                                                                          16,\n",
       "                                                                                          17,\n",
       "                                                                                          18,\n",
       "                                                                                          19,\n",
       "                                                                                          20,\n",
       "                                                                                          21,\n",
       "                                                                                          22,\n",
       "                                                                                          23,\n",
       "                                                                                          24,\n",
       "                                                                                          25,\n",
       "                                                                                          26,\n",
       "                                                                                          27,\n",
       "                                                                                          28,\n",
       "                                                                                          29],\n",
       "                                                                    'splitter': ['best',\n",
       "                                                                                 'random']}},\n",
       "               generations=30, verbosity=2)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpotw.fit(Xw_train, yw_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a1fdbc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.912621359223301\n"
     ]
    }
   ],
   "source": [
    "print(tpot.score(Xw_test, yw_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95cf7fa",
   "metadata": {},
   "source": [
    "# Third heuristic: Hyperopt-sklearn (with env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f340b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/hyperopt/hyperopt-sklearn\n",
      "  Cloning https://github.com/hyperopt/hyperopt-sklearn to /private/var/folders/35/9x_5dznn4pz7j06jf9frns8w0000gn/T/pip-req-build-_x5trq66\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/hyperopt/hyperopt-sklearn /private/var/folders/35/9x_5dznn4pz7j06jf9frns8w0000gn/T/pip-req-build-_x5trq66\n",
      "  Resolved https://github.com/hyperopt/hyperopt-sklearn to commit 4bc286479677a0bfd2178dac4546ea268b3f3b77\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: hyperopt>=0.2.6 in /Users/islambendaoud/opt/anaconda3/lib/python3.8/site-packages (from hpsklearn==1.0.3) (0.2.7)\n",
      "INFO: pip is looking at multiple versions of hpsklearn to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.25.0 Requires-Python >=3.9; 1.25.0rc1 Requires-Python >=3.9; 1.25.1 Requires-Python >=3.9; 1.25.2 Requires-Python >=3.9; 1.26.0 Requires-Python <3.13,>=3.9; 1.26.0b1 Requires-Python <3.13,>=3.9; 1.26.0rc1 Requires-Python <3.13,>=3.9; 1.26.1 Requires-Python <3.13,>=3.9; 1.26.2 Requires-Python >=3.9; 1.26.3 Requires-Python >=3.9\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement numpy>=1.26.0 (from hpsklearn) (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.21.2, 1.21.3, 1.21.4, 1.21.5, 1.21.6, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.23.0rc1, 1.23.0rc2, 1.23.0rc3, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.24.0rc1, 1.24.0rc2, 1.24.0, 1.24.1, 1.24.2, 1.24.3, 1.24.4)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for numpy>=1.26.0\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/hyperopt/hyperopt-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d268bbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'decision_tree_classifier' from 'hpsklearn' (/Users/islambendaoud/opt/anaconda3/lib/python3.8/site-packages/hpsklearn/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bd4042304c7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhpsklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHyperoptEstimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecision_tree_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_discriminant_analysis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaussian_nb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogistic_regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhyperopt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'decision_tree_classifier' from 'hpsklearn' (/Users/islambendaoud/opt/anaconda3/lib/python3.8/site-packages/hpsklearn/__init__.py)"
     ]
    }
   ],
   "source": [
    "from hpsklearn import HyperoptEstimator, decision_tree_classifier, linear_discriminant_analysis, gaussian_nb, svc, logistic_regression\n",
    "from hyperopt import hp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eeef1a3",
   "metadata": {},
   "source": [
    "**Note: Does not work on LDA.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04656aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We made four runs with these seeds:\n",
    "seeds = [42, 36541, 4511451]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4102fe46",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f3341ae",
   "metadata": {},
   "source": [
    "### HPO on the various algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e33dc5",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07ccd6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.19s/trial, best loss: 0.017985611510791366]\n",
      "100%|██████████| 2/2 [00:05<00:00,  5.28s/trial, best loss: 0.017985611510791366]\n",
      "100%|██████████| 3/3 [00:04<00:00,  4.97s/trial, best loss: 0.017985611510791366]\n",
      "100%|██████████| 4/4 [00:05<00:00,  5.45s/trial, best loss: 0.017985611510791366]\n",
      "100%|██████████| 5/5 [00:04<00:00,  4.92s/trial, best loss: 0.017985611510791366]\n",
      "100%|██████████| 6/6 [00:05<00:00,  5.43s/trial, best loss: 0.017985611510791366]\n",
      "100%|██████████| 7/7 [00:06<00:00,  6.64s/trial, best loss: 0.017985611510791366]\n",
      "100%|██████████| 8/8 [00:07<00:00,  7.28s/trial, best loss: 0.017985611510791366]\n",
      "100%|██████████| 9/9 [00:05<00:00,  5.14s/trial, best loss: 0.017985611510791366]\n",
      "100%|██████████| 10/10 [00:04<00:00,  4.57s/trial, best loss: 0.017985611510791366]\n",
      "Logistic_regression score : 0.9762675296655879\n",
      "Best model : {'learner': DecisionTreeClassifier(criterion='entropy', random_state=2, splitter='random'), 'preprocs': (Normalizer(),), 'ex_preprocs': ()}\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\x-app\\Anaconda3\\envs\\tp_mlops\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but Normalizer was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\x-app\\Anaconda3\\envs\\tp_mlops\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but Normalizer was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.56s/trial, best loss: 0.04106714628297359]\n",
      "100%|██████████| 2/2 [00:06<00:00,  6.00s/trial, best loss: 0.027877697841726667]\n",
      "100%|██████████| 3/3 [00:10<00:00, 10.66s/trial, best loss: 0.027877697841726667]\n",
      "100%|██████████| 4/4 [00:10<00:00, 10.16s/trial, best loss: 0.027877697841726667]\n",
      "100%|██████████| 5/5 [00:09<00:00,  9.62s/trial, best loss: 0.027877697841726667]\n",
      "100%|██████████| 6/6 [00:07<00:00,  7.77s/trial, best loss: 0.027877697841726667]\n",
      "100%|██████████| 7/7 [00:08<00:00,  8.29s/trial, best loss: 0.027877697841726667]\n",
      "100%|██████████| 8/8 [00:07<00:00,  7.61s/trial, best loss: 0.027877697841726667]\n",
      "100%|██████████| 9/9 [00:08<00:00,  8.69s/trial, best loss: 0.027877697841726667]\n",
      "100%|██████████| 10/10 [00:08<00:00,  8.28s/trial, best loss: 0.027877697841726667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\x-app\\Anaconda3\\envs\\tp_mlops\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\x-app\\Anaconda3\\envs\\tp_mlops\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic_regression score : 0.9741100323624595\n",
      "Best model : {'learner': DecisionTreeClassifier(criterion='entropy', max_depth=2, random_state=0), 'preprocs': (StandardScaler(),), 'ex_preprocs': ()}\n",
      "100%|██████████| 1/1 [00:09<00:00,  9.23s/trial, best loss: 0.01888489208633093]\n",
      "100%|██████████| 2/2 [00:07<00:00,  7.69s/trial, best loss: 0.01888489208633093]\n",
      "100%|██████████| 3/3 [00:08<00:00,  8.10s/trial, best loss: 0.01888489208633093]\n",
      "100%|██████████| 4/4 [00:08<00:00,  8.89s/trial, best loss: 0.016786570743405282]\n",
      "100%|██████████| 5/5 [00:08<00:00,  8.61s/trial, best loss: 0.016786570743405282]\n",
      "100%|██████████| 6/6 [00:11<00:00, 11.92s/trial, best loss: 0.016786570743405282]\n",
      "100%|██████████| 7/7 [00:08<00:00,  8.18s/trial, best loss: 0.016786570743405282]\n",
      "100%|██████████| 8/8 [00:07<00:00,  7.66s/trial, best loss: 0.016786570743405282]\n",
      "100%|██████████| 9/9 [00:07<00:00,  7.55s/trial, best loss: 0.016786570743405282]\n",
      "100%|██████████| 10/10 [00:09<00:00,  9.61s/trial, best loss: 0.016786570743405282]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\x-app\\Anaconda3\\envs\\tp_mlops\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but PCA was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\x-app\\Anaconda3\\envs\\tp_mlops\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but PCA was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic_regression score : 0.9795037756202805\n",
      "Best model : {'learner': DecisionTreeClassifier(max_features=0.6016283442771942, max_leaf_nodes=15,\n",
      "                       random_state=4, splitter='random'), 'preprocs': (PCA(n_components=76, whiten=True),), 'ex_preprocs': ()}\n",
      "dt_scores : [0.9762675296655879, 0.9741100323624595, 0.9795037756202805]\n",
      "dt_train_scores : [1.0, 0.9740376543950114, 0.9829116200983331]\n"
     ]
    }
   ],
   "source": [
    "dt_scores = []\n",
    "dt_train_scores = []\n",
    "for seed in seeds:\n",
    "    estim_dt = HyperoptEstimator( classifier=decision_tree_classifier('my_decision_tree_classifier'), seed=seed)\n",
    "    estim_dt.fit(Xv_train, yv_train)\n",
    "    dt_score = estim_dt.score(Xv_test, yv_test)\n",
    "    dt_scores.append(dt_score)\n",
    "    print(f\"Logistic_regression score : {dt_score}\")\n",
    "    print(f\"Best model : {estim_dt.best_model()}\")\n",
    "    dt_train_score = estim_dt.score(Xv_train, yv_train)\n",
    "    dt_train_scores.append(dt_train_score)\n",
    "print(f\"dt_scores : {dt_scores}\")\n",
    "print(f\"dt_train_scores : {dt_train_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa048c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9762675296655879, 0.9741100323624595, 0.9795037756202805]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c74b3c",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a626ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.63s/trial, best loss: 0.05725419664268583]\n",
      "100%|██████████| 2/2 [00:12<00:00, 12.61s/trial, best loss: 0.05725419664268583]\n",
      "100%|██████████| 3/3 [00:13<00:00, 13.32s/trial, best loss: 0.05725419664268583]\n",
      "100%|██████████| 4/4 [00:12<00:00, 12.80s/trial, best loss: 0.05725419664268583]\n",
      "100%|██████████| 5/5 [01:06<00:00, 66.99s/trial, best loss: 0.02877697841726623]\n",
      "100%|██████████| 6/6 [00:14<00:00, 14.60s/trial, best loss: 0.02877697841726623]\n",
      "100%|██████████| 7/7 [00:12<00:00, 12.36s/trial, best loss: 0.02877697841726623]\n",
      "100%|██████████| 8/8 [02:00<00:00, 120.28s/trial, best loss: 0.02877697841726623]\n",
      "100%|██████████| 9/9 [00:22<00:00, 22.88s/trial, best loss: 0.02877697841726623]\n",
      "100%|██████████| 10/10 [00:11<00:00, 11.24s/trial, best loss: 0.02877697841726623]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\x-app\\Anaconda3\\envs\\tp_mlops\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\x-app\\Anaconda3\\envs\\tp_mlops\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\x-app\\Anaconda3\\envs\\tp_mlops\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic_regression score : 0.9757281553398058\n",
      "Best model : {'learner': LogisticRegression(C=0.8441780584655098, max_iter=558, n_jobs=1, random_state=1,\n",
      "                   solver='sag', tol=0.00024159208827165694), 'preprocs': (StandardScaler(),), 'ex_preprocs': ()}\n",
      "100%|██████████| 1/1 [00:20<00:00, 20.00s/trial, best loss: 0.04436450839328532]\n",
      "100%|██████████| 2/2 [00:10<00:00, 10.35s/trial, best loss: 0.04436450839328532]\n",
      "100%|██████████| 3/3 [00:29<00:00, 29.67s/trial, best loss: 0.04136690647482011]\n",
      "100%|██████████| 4/4 [00:21<00:00, 21.04s/trial, best loss: 0.04136690647482011]\n",
      "100%|██████████| 5/5 [00:19<00:00, 19.93s/trial, best loss: 0.04136690647482011]\n",
      "100%|██████████| 6/6 [00:07<00:00,  7.05s/trial, best loss: 0.04136690647482011]\n",
      "100%|██████████| 7/7 [00:08<00:00,  8.67s/trial, best loss: 0.04136690647482011]\n",
      "100%|██████████| 8/8 [00:20<00:00, 20.57s/trial, best loss: 0.04136690647482011]\n",
      "100%|██████████| 9/9 [00:10<00:00, 10.03s/trial, best loss: 0.04136690647482011]\n",
      "100%|██████████| 10/10 [00:54<00:00, 54.44s/trial, best loss: 0.039868105515587504]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\x-app\\Anaconda3\\envs\\tp_mlops\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\x-app\\Anaconda3\\envs\\tp_mlops\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic_regression score : 0.9590075512405609\n",
      "Best model : {'learner': LogisticRegression(C=1.1308093890779032, max_iter=756, n_jobs=1, penalty='l1',\n",
      "                   random_state=2, solver='liblinear',\n",
      "                   tol=2.9100307874096604e-05), 'preprocs': (MinMaxScaler(clip=True, feature_range=(0.0, 1.0)),), 'ex_preprocs': ()}\n",
      "100%|██████████| 1/1 [00:13<00:00, 13.30s/trial, best loss: 0.05725419664268583]\n",
      "100%|██████████| 2/2 [08:42<00:00, 522.63s/trial, best loss: 0.031175059952038398]\n",
      "100%|██████████| 3/3 [00:17<00:00, 17.23s/trial, best loss: 0.020383693045563533]\n",
      "100%|██████████| 4/4 [00:14<00:00, 14.96s/trial, best loss: 0.020383693045563533]\n",
      "100%|██████████| 5/5 [00:25<00:00, 25.17s/trial, best loss: 0.020383693045563533]\n",
      "100%|██████████| 6/6 [02:24<00:00, 144.69s/trial, best loss: 0.020383693045563533]\n",
      "100%|██████████| 7/7 [00:18<00:00, 18.86s/trial, best loss: 0.020383693045563533]\n",
      "100%|██████████| 8/8 [00:09<00:00,  9.82s/trial, best loss: 0.020383693045563533]\n",
      "100%|██████████| 9/9 [00:11<00:00, 11.32s/trial, best loss: 0.020383693045563533]\n",
      "100%|██████████| 10/10 [00:16<00:00, 16.17s/trial, best loss: 0.01918465227817745]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\x-app\\Anaconda3\\envs\\tp_mlops\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but PCA was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\x-app\\Anaconda3\\envs\\tp_mlops\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but PCA was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic_regression score : 0.9784250269687162\n",
      "Best model : {'learner': LogisticRegression(C=1.0424179853175266, max_iter=708, n_jobs=1, random_state=0,\n",
      "                   solver='newton-cg', tol=0.0008337271595944857), 'preprocs': (PCA(n_components=4, whiten=True),), 'ex_preprocs': ()}\n",
      "Logistic_regression score : [0.9757281553398058, 0.9590075512405609, 0.9784250269687162]\n",
      "Logistic_regression train score : [0.9818923132270057, 0.9584482551864733, 0.9817723947715553]\n"
     ]
    }
   ],
   "source": [
    "lr_scores = []\n",
    "lr_train_scores = []\n",
    "for seed in seeds:\n",
    "    estim_lr = HyperoptEstimator( classifier=logistic_regression('my_logistic_regression'), seed=seed)\n",
    "    estim_lr.fit(Xv_train, yv_train)\n",
    "    lr_score = estim_lr.score(Xv_test, yv_test)\n",
    "    lr_scores.append(lr_score)\n",
    "    print(f\"Logistic_regression score : {lr_score}\")\n",
    "    print(f\"Best model : {estim_lr.best_model()}\")\n",
    "    lr_train_score = estim_lr.score(Xv_train, yv_train)\n",
    "    lr_train_scores.append(lr_train_score)\n",
    "print(f\"Logistic_regression score : {lr_scores}\")\n",
    "print(f\"Logistic_regression train score : {lr_train_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47519e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic_regression score : [0.9757281553398058, 0.9590075512405609, 0.9784250269687162]\n",
      "Logistic_regression train score : [0.9818923132270057, 0.9584482551864733, 0.9817723947715553]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Logistic_regression score : {lr_scores}\")\n",
    "print(f\"Logistic_regression train score : {lr_train_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049041c6",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c009ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.37s/trial, best loss: 0.16936450839328532]\n",
      "100%|██████████| 2/2 [00:04<00:00,  4.75s/trial, best loss: 0.05455635491606714]\n",
      "100%|██████████| 3/3 [00:05<00:00,  5.19s/trial, best loss: 0.04166666666666663]\n",
      "100%|██████████| 4/4 [00:05<00:00,  5.19s/trial, best loss: 0.04166666666666663]\n",
      "100%|██████████| 5/5 [00:05<00:00,  5.29s/trial, best loss: 0.04166666666666663]\n",
      "100%|██████████| 6/6 [00:07<00:00,  7.78s/trial, best loss: 0.03627098321342925]\n",
      "100%|██████████| 7/7 [00:06<00:00,  6.52s/trial, best loss: 0.03627098321342925]\n",
      "100%|██████████| 8/8 [00:06<00:00,  6.14s/trial, best loss: 0.03627098321342925]\n",
      "100%|██████████| 9/9 [00:07<00:00,  7.32s/trial, best loss: 0.03627098321342925]\n",
      "100%|██████████| 10/10 [00:07<00:00,  7.54s/trial, best loss: 0.03627098321342925]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\x-app\\Anaconda3\\envs\\tp_mlops\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but PCA was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\x-app\\Anaconda3\\envs\\tp_mlops\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but PCA was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes score : 0.9606256742179072\n",
      "Best model : {'learner': GaussianNB(), 'preprocs': (PCA(n_components=28),), 'ex_preprocs': ()}\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.04s/trial, best loss: 0.16936450839328532]\n",
      "100%|██████████| 2/2 [00:05<00:00,  5.13s/trial, best loss: 0.03627098321342925]\n",
      "100%|██████████| 3/3 [00:04<00:00,  4.91s/trial, best loss: 0.03627098321342925]\n",
      "100%|██████████| 4/4 [00:04<00:00,  4.96s/trial, best loss: 0.03627098321342925]\n",
      "100%|██████████| 5/5 [00:05<00:00,  5.65s/trial, best loss: 0.03627098321342925]\n",
      "100%|██████████| 6/6 [00:05<00:00,  5.56s/trial, best loss: 0.03627098321342925]\n",
      "100%|██████████| 7/7 [00:06<00:00,  6.11s/trial, best loss: 0.03627098321342925]\n",
      "100%|██████████| 8/8 [00:06<00:00,  6.84s/trial, best loss: 0.03627098321342925]\n",
      "100%|██████████| 9/9 [00:06<00:00,  6.14s/trial, best loss: 0.03627098321342925]\n",
      "100%|██████████| 10/10 [00:04<00:00,  4.98s/trial, best loss: 0.03627098321342925]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\x-app\\Anaconda3\\envs\\tp_mlops\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but PCA was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\x-app\\Anaconda3\\envs\\tp_mlops\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but PCA was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes score : 0.9606256742179072\n",
      "Best model : {'learner': GaussianNB(), 'preprocs': (PCA(n_components=76),), 'ex_preprocs': ()}\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.12s/trial, best loss: 0.99310551558753]\n",
      " 50%|█████     | 1/2 [00:04<?, ?trial/s, best loss=?]\n",
      "Gaussian Naive Bayes score : 0.012405609492988134\n",
      "Best model : {'learner': GaussianNB(), 'preprocs': (Normalizer(norm='l1'),), 'ex_preprocs': ()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\x-app\\Anaconda3\\envs\\tp_mlops\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but Normalizer was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\x-app\\Anaconda3\\envs\\tp_mlops\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but Normalizer was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.11s/trial, best loss: 0.036870503597122295]\n",
      " 50%|█████     | 1/2 [00:04<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\x-app\\Anaconda3\\envs\\tp_mlops\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\x-app\\Anaconda3\\envs\\tp_mlops\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes score : 0.9606256742179072\n",
      "Best model : {'learner': GaussianNB(), 'preprocs': (StandardScaler(with_std=False),), 'ex_preprocs': ()}\n",
      "gnb_scores : [0.9606256742179072, 0.9606256742179072, 0.012405609492988134, 0.9606256742179072]\n",
      "gnb_train_scores : [0.9631850341767598, 0.9631850341767598, 0.012711356277731144, 0.9629451972658593]\n"
     ]
    }
   ],
   "source": [
    "gnb_scores = []\n",
    "gnb_train_scores = []\n",
    "for seed in seeds:\n",
    "    estim_gnb = HyperoptEstimator( classifier=gaussian_nb('my_gnb'), seed=seed)\n",
    "    estim_gnb.fit(Xv_train, yv_train)\n",
    "    gnb_score = estim_gnb.score(Xv_test, yv_test)\n",
    "    gnb_scores.append(gnb_score)\n",
    "    print(f\"Gaussian Naive Bayes score : {gnb_score}\")\n",
    "    print(f\"Best model : {estim_gnb.best_model()}\")\n",
    "    gnb_train_score = estim_gnb.score(Xv_train, yv_train)\n",
    "    gnb_train_scores.append(gnb_train_score)\n",
    "print(f\"gnb_scores : {gnb_scores}\")\n",
    "print(f\"gnb_train_scores : {gnb_train_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b062357",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c0f01c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    }
   ],
   "source": [
    "svc_scores = []\n",
    "svc_train_scores = []\n",
    "for seed in seeds:\n",
    "    estim_svc = HyperoptEstimator( classifier=svc('my_svc'), seed=seed)\n",
    "    estim_svc.fit(Xv_train, yv_train)\n",
    "    svc_score = estim_svc.score(Xv_test, yv_test)\n",
    "    svc_scores.append(svc_score)\n",
    "    print(f\"SVC score : {svc_score}\")\n",
    "    print(f\"Best model : {estim_svc.best_model()}\")\n",
    "    svc_train_score = estim_svc.score(Xv_train, yv_train)\n",
    "    svc_train_scores.append(svc_train_score)\n",
    "print(f\"svc_scores : {svc_scores}\")\n",
    "print(f\"svc_train_scores : {svc_train_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0addd157",
   "metadata": {},
   "source": [
    "### LDA : does not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6be0ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.91s/trial, best loss: 0.01978417266187049]\n",
      " 50%|█████     | 1/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: The leading minor of order 17 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:04<?, ?trial/s, best loss=?]\n",
      "The leading minor of order 17 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    estim_lda = HyperoptEstimator( classifier=linear_discriminant_analysis('my_lda'))\n",
    "    estim_lda.fit(Xv_train, yv_train)\n",
    "    print(f\"LDA score : {estim_lda.score(Xv_test, yv_test)}\")\n",
    "    print(f\"Best model : {estim_lda.best_model()}\")\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beca34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot of all test scores :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6284d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9789644012944984,\n",
       "  0.9848975188781014,\n",
       "  0.9757281553398058,\n",
       "  0.9832793959007551],\n",
       " [0.97680690399137,\n",
       "  0.9741100323624595,\n",
       "  0.9590075512405609,\n",
       "  0.9606256742179072],\n",
       " [0.9606256742179072,\n",
       "  0.9606256742179072,\n",
       "  0.9606256742179072,\n",
       "  0.9606256742179072],\n",
       " [0.9832793959007551,\n",
       "  0.9789644012944984,\n",
       "  0.9800431499460626,\n",
       "  0.9832793959007551]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dt_scores, lr_scores, gnb_scores, svc_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78e7bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot([dt_scores, lr_scores, gnb_scores, svc_scores], labels=['Decision Tree', 'Logistic Regression', 'GaussianNB', 'SVC'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b6b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([dt_train_scores, lr_train_scores, gnb_train_scores, svc__train_scores], labels=['Decision Tree', 'Logistic Regression', 'GaussianNB', 'SVC'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdaa437",
   "metadata": {},
   "source": [
    "### Scores for HPO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50101263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree value</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression Value</td>\n",
       "      <td>0.971744</td>\n",
       "      <td>0.967638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaussian Naive Bayes value</td>\n",
       "      <td>0.963185</td>\n",
       "      <td>0.960626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC value</td>\n",
       "      <td>0.987289</td>\n",
       "      <td>0.981392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Training Accuracy  Test Accuracy\n",
       "0         Decision Tree value           1.000000       0.980717\n",
       "1   Logistic Regression Value           0.971744       0.967638\n",
       "2  Gaussian Naive Bayes value           0.963185       0.960626\n",
       "3                   SVC value           0.987289       0.981392"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With means\n",
    "results_hpo_df_means = pd.DataFrame({\n",
    "    'Model': ['Decision Tree value', 'Logistic Regression Value','Gaussian Naive Bayes value', 'SVC value'],\n",
    "    'Training Accuracy': [np.mean(dt_train_scores), np.mean(lr_train_scores), np.mean(gnb_train_scores), np.mean(svc_train_scores)],\n",
    "    'Test Accuracy': [np.mean(dt_scores), np.mean(lr_scores), np.mean(gnb_scores), np.mean(svc_scores)]\n",
    "})\n",
    "results_hpo_df_means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d40a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree value</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression Value</td>\n",
       "      <td>0.969841</td>\n",
       "      <td>0.967368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaussian Naive Bayes value</td>\n",
       "      <td>0.963185</td>\n",
       "      <td>0.960626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC value</td>\n",
       "      <td>0.985280</td>\n",
       "      <td>0.981661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Training Accuracy  Test Accuracy\n",
       "0         Decision Tree value           1.000000       0.981122\n",
       "1   Logistic Regression Value           0.969841       0.967368\n",
       "2  Gaussian Naive Bayes value           0.963185       0.960626\n",
       "3                   SVC value           0.985280       0.981661"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With medians\n",
    "results_hpo_df_medians = pd.DataFrame({\n",
    "    'Model': ['Decision Tree value', 'Logistic Regression Value','Gaussian Naive Bayes value', 'SVC value'],\n",
    "    'Training Accuracy': [np.median(dt_train_scores), np.median(lr_train_scores), np.median(gnb_train_scores), np.median(svc_train_scores)],\n",
    "    'Test Accuracy': [np.median(dt_scores), np.median(lr_scores), np.median(gnb_scores), np.median(svc_scores)]\n",
    "})\n",
    "results_hpo_df_medians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55303595",
   "metadata": {},
   "source": [
    "### Multiple classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d78275c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = hp.pchoice( 'my_classifiers', \n",
    "          [ (0.25, decision_tree_classifier('my_classifiers.decision_tree_classifier') ), \n",
    "            (0.25, gaussian_nb('my_classifiers.gnb') ), \n",
    "            (0.25, svc('my_classifiers.svc') ), \n",
    "            (0.25, logistic_regression('my_classifiers.lr'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d42bd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.35s/trial, best loss: 0.016786570743405282]\n",
      "100%|██████████| 2/2 [00:07<00:00,  7.79s/trial, best loss: 0.016786570743405282]\n",
      "100%|██████████| 3/3 [00:04<00:00,  4.91s/trial, best loss: 0.016786570743405282]\n",
      "100%|██████████| 4/4 [00:05<00:00,  5.49s/trial, best loss: 0.016786570743405282]\n",
      "100%|██████████| 5/5 [00:05<00:00,  5.40s/trial, best loss: 0.016786570743405282]\n",
      "100%|██████████| 6/6 [00:07<00:00,  7.45s/trial, best loss: 0.016786570743405282]\n",
      "100%|██████████| 7/7 [00:08<00:00,  8.09s/trial, best loss: 0.016786570743405282]\n",
      "100%|██████████| 8/8 [00:04<00:00,  4.86s/trial, best loss: 0.016786570743405282]\n",
      "100%|██████████| 9/9 [00:05<00:00,  5.92s/trial, best loss: 0.016786570743405282]\n",
      "100%|██████████| 10/10 [00:15<00:00, 15.71s/trial, best loss: 0.016786570743405282]\n",
      "Best model : {'learner': SVC(C=1.1949957655455028, coef0=0.763452406794348, degree=2, random_state=3,\n",
      "    shrinking=False, tol=0.0023561475053219647), 'preprocs': (PCA(n_components=76),), 'ex_preprocs': ()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\x-app\\Anaconda3\\envs\\tp_mlops\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but PCA was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy : 0.9832793959007551\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.14s/trial, best loss: 0.05725419664268583]\n",
      "100%|██████████| 2/2 [00:06<00:00,  6.58s/trial, best loss: 0.05725419664268583]\n",
      "100%|██████████| 3/3 [00:27<00:00, 27.49s/trial, best loss: 0.029376498800959272]\n",
      "100%|██████████| 4/4 [00:04<00:00,  4.20s/trial, best loss: 0.01948441247002397]\n",
      "100%|██████████| 5/5 [00:06<00:00,  6.47s/trial, best loss: 0.01948441247002397]\n",
      " 83%|████████▎ | 5/6 [00:00<?, ?trial/s, best loss=?]"
     ]
    }
   ],
   "source": [
    "classifiers_scores = []\n",
    "for seed in seeds:\n",
    "    estim2 = HyperoptEstimator( classifier=clf, seed=seed)\n",
    "    estim2.fit(Xv_train, yv_train)\n",
    "    print(f\"Best model : {estim2.best_model()}\")\n",
    "    classifiers_score = estim2.score(Xv_test, yv_test)\n",
    "    print(f\"Test accuracy : {classifiers_score}\")\n",
    "    classifiers_scores.append(classifiers_score)\n",
    "print(f\"classifiers_scores : {classifiers_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7407ad36",
   "metadata": {},
   "source": [
    "{'learner': DecisionTreeClassifier(max_features=0.29416369047394064, max_leaf_nodes=15,\n",
    "                       random_state=3), 'preprocs': (MinMaxScaler(clip=True, feature_range=(-1.0, 1.0)),), 'ex_preprocs': ()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ddfccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean of scores : {np.mean(classifiers_scores)}, median of scores : {np.median(classifiers_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c220877",
   "metadata": {},
   "source": [
    "### Base scores :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3591a413",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_scores_df = pd.DataFrame({\n",
    "    'Algorithm': ['DecisionTree', 'Logistic Regression','Gaussian Naive Bayes', 'SVC', 'LDA'],\n",
    "    'Accuracy Dwage': [0.925, 0.933, 0.937, 0.937, 0.931],\n",
    "    'Accuracy Dvalue': [0.981, 0.960, 0.970, 0.970, 0.980]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1db6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy Dwage</th>\n",
       "      <th>Accuracy Dvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Algorithm  Accuracy Dwage  Accuracy Dvalue\n",
       "0          DecisionTree           0.925            0.981\n",
       "1   Logistic Regression           0.933            0.960\n",
       "2  Gaussian Naive Bayes           0.937            0.970\n",
       "3                   SVC           0.937            0.970\n",
       "4                   LDA           0.931            0.980"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f21dd49",
   "metadata": {},
   "source": [
    "### Scores for all automl algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0317b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_total_df = pd.DataFrame({\n",
    "    'Model': ['Decision Tree value', 'Logistic Regression Value','Gaussian Naive Bayes value', 'SVC value', 'LDA Value'],\n",
    "    'Base Test Accuracy': [0.981, 0.960, 0.970, 0.970, 0.980],\n",
    "    'Random Search Test Accuracy': [0.978, '-', '-', '-', 0.975],\n",
    "    'Hyperopt-sklearn test accuracy': [np.mean(dt_score), np.mean(lr_score), np.mean(gnb_score), np.mean(svc_score), '-']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e922ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Base Test Accuracy</th>\n",
       "      <th>Random Search Test Accuracy</th>\n",
       "      <th>Hyperopt-sklearn test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree value</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.975189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression Value</td>\n",
       "      <td>0.960</td>\n",
       "      <td>-</td>\n",
       "      <td>0.957389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaussian Naive Bayes value</td>\n",
       "      <td>0.970</td>\n",
       "      <td>-</td>\n",
       "      <td>0.960626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC value</td>\n",
       "      <td>0.970</td>\n",
       "      <td>-</td>\n",
       "      <td>0.980583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LDA Value</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.975</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Base Test Accuracy Random Search Test Accuracy  \\\n",
       "0         Decision Tree value               0.981                       0.978   \n",
       "1   Logistic Regression Value               0.960                           -   \n",
       "2  Gaussian Naive Bayes value               0.970                           -   \n",
       "3                   SVC value               0.970                           -   \n",
       "4                   LDA Value               0.980                       0.975   \n",
       "\n",
       "  Hyperopt-sklearn test accuracy  \n",
       "0                       0.975189  \n",
       "1                       0.957389  \n",
       "2                       0.960626  \n",
       "3                       0.980583  \n",
       "4                              -  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc410f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7da407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90973c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e53a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef7b720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6085f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4725a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc995ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce6e14d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4e2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
